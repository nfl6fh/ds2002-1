{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea2cdb3",
   "metadata": {},
   "source": [
    "## Using Python to Interact with MongoDB\n",
    "This notebook demonstrates basic functioality of MongoDB by way of the **pymongo** library.  As it's name implies, pymongo is the MongoDB library for Python, and its **documnentation** can be found here: https://pymongo.readthedocs.io/en/stable/index.html\n",
    "\n",
    "### 1.0. Prerequisites\n",
    "\n",
    "#### 1.1. First, you must install the *pymongo* libary into your *python* environment by executing the following command in a *Terminal window*\n",
    "-  python -m pip install pymongo[srv]\n",
    "\n",
    "#### 1.2. Next, as with all Jupyter Notebooks, you need to **Import** the libaries that you'll be working with in the notebook,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc749762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /Users/JAWILLI/opt/anaconda3/lib/python3.9/site-packages (4.3.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/JAWILLI/opt/anaconda3/lib/python3.9/site-packages (from pymongo) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90fde494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pymongo\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc48a6f",
   "metadata": {},
   "source": [
    "### 2.0. Connecting to the MongoDB Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0554d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = \"localhost\"\n",
    "port = \"27017\"\n",
    "\n",
    "atlas_cluster_name = \"sandbox\"\n",
    "atlas_default_dbname = \"local\"\n",
    "#atlas_user_name = \"m001-student\"\n",
    "#atlas_password = \"m001-mongodb-basics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffc52ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Connection String: mongodb://localhost:27017/\n"
     ]
    }
   ],
   "source": [
    "conn_str = {\n",
    "    \"local\" : f\"mongodb://{host_name}:{port}/\",\n",
    "#    \"atlas\" : f\"mongodb+srv://{atlas_user_name}:{atlas_password}@{atlas_cluster_name}.zibbf.mongodb.net/{atlas_default_dbname}\"\n",
    "}\n",
    "\n",
    "client = pymongo.MongoClient(conn_str[\"local\"])\n",
    "\n",
    "print(f\"Local Connection String: {conn_str['local']}\")\n",
    "#print(f\"Atlas Connection String: {conn_str['atlas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f9ae8",
   "metadata": {},
   "source": [
    "### 3.0. Creating Databases, Collections, and Documents\n",
    "MongoDB creates objects lazily. In other words, databases and collections (somewhat equivalent to a table) are only created on the server when the first document (equivalent to a row or record) is inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4b710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'ds2002', 'local', 'mydb', 'test']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"blog\"\n",
    "\n",
    "db = client[db_name]\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1f9e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83a734",
   "metadata": {},
   "source": [
    "Here we see that even though we're referencing a new database named **blog**, it isn't returned when we query the server for the databases it's serving. \n",
    "\n",
    "Now let's create a new collection called **posts** by inserting one new **document** using the **insert_one( )** function.  Notice that the **document** being inserted is structured similarly to a Python **dictionary**.  This is no accident!  Both make use of **JavaScript Object Notation (JSON)**.  If you pay careful attention, you'll notice that a one-to-many relationship has been modeled by *nesting* related entities within a **List**.  Here, the relationship between one **author** and many **tags** has been modeled.  We've also inserted a Python-native **datetime** value into the document. This works because MongoDB is actually based on **Binary JavaScript Object Notation (BSON)**, an interchange format created by the developers of MongoDB.  Like JSON, BSON supports the embedding of documents and arrays within other documents and arrays; however, BSON also contains extensions that allow representation of data types that are not part of the JSON specification.  You can learn more about BSON at: https://bsonspec.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9f2393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID:  6362e2378130e5fb6aa1aa46\n"
     ]
    }
   ],
   "source": [
    "post = {\"author\": \"Mike\",\n",
    "        \"text\": \"My first blog post!\",\n",
    "        \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n",
    "        \"date\": datetime.datetime.utcnow()\n",
    "       }\n",
    "\n",
    "posts = db.posts\n",
    "post_id = posts.insert_one(post).inserted_id\n",
    "\n",
    "print(\"Document ID: \", post_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a48ea",
   "metadata": {},
   "source": [
    "Now when we query the client for lists of the databases & collections on the server we see our new database **blog**, and our new collection **posts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102decf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases:  ['admin', 'blog', 'config', 'local', 'mydb', 'test']\n",
      "Collections:  ['posts']\n"
     ]
    }
   ],
   "source": [
    "print(\"Databases: \", client.list_database_names())\n",
    "print(\"Collections: \", db.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91009c48",
   "metadata": {},
   "source": [
    "### 4.0. Querying MongoDB\n",
    "Of course the next thing we'll be interested in, is to query the **collection**.  Here we retrieve the document we just **inserted**. You may notice that we're not really specifying a query, but because there is only one document in the **collection** it will be returned anyway. If there had been no documents in the **collection** then the result would have been **None**.  We're also makine use of the **pprint** (pretty print) library to format our results so they're easily readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4159ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(posts.find_one({}))\n",
    "#print(posts.find_one({}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ca214",
   "metadata": {},
   "source": [
    "Of course it's possible to **insert** more than one **document** at a time.  This is achieved by placing the **documents** into a Python **List**, and then passing them to the **insert_many( )** function. What's more, because MongoDB is designed to support *polyschematism* the new documents we insert aren't required to have matching structures (schemas).  Notice that the first document below has no **title** element, and the second document has no **tags** element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a605e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectId('6362e3038130e5fb6aa1aa47'), ObjectId('6362e3038130e5fb6aa1aa48')]\n"
     ]
    }
   ],
   "source": [
    "new_posts = [{\"author\": \"Mike\",\n",
    "          \"text\": \"Another post!\",\n",
    "          \"tags\": [\"bulk\", \"insert\"],\n",
    "          \"date\": datetime.datetime(2009, 11, 12, 11, 14)\n",
    "         },\n",
    "         {\"author\": \"Eliot\",\n",
    "          \"title\": \"MongoDB is fun\",\n",
    "          \"text\": \"and pretty easy too!\",\n",
    "          \"date\": datetime.datetime(2009, 11, 10, 10, 45)\n",
    "         }]\n",
    "\n",
    "result = posts.insert_many(new_posts)\n",
    "pprint.pprint(result.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca0e69",
   "metadata": {},
   "source": [
    "Now it's possible to query for specific documents by using JSON **documents** or even simple **key : value** pair notations (which are actually simple JSON documents).  First, using the **find_one( )** method the first occurance that matches the specified criterea will be returned. To ensure you get exactly the **document** you want, you can use its ObjectID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92481b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(posts.find_one( {\"author\" : \"Mike\"} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7078e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(posts.find_one( {\"_id\" : post_id} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29431c09",
   "metadata": {},
   "source": [
    "It's also possible to iterate over multiple **documents** by way of the **find( )** method, which returns a cursor containing references to multiple documents.  The MongoDB equivalent of the SQL query **SELECT * FROM posts** is achieved by calling the **find( )** function with no argument at all, and he MongoDB equivalent of **SELECT * FROM posts WHERE author = 'Mike'** is achieved by passing the simple JSON document **{\"author\" : \"Mike\"}**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd9b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n",
      "{'_id': ObjectId('6362e3038130e5fb6aa1aa47'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2009, 11, 12, 11, 14),\n",
      " 'tags': ['bulk', 'insert'],\n",
      " 'text': 'Another post!'}\n",
      "{'_id': ObjectId('6362e3038130e5fb6aa1aa48'),\n",
      " 'author': 'Eliot',\n",
      " 'date': datetime.datetime(2009, 11, 10, 10, 45),\n",
      " 'text': 'and pretty easy too!',\n",
      " 'title': 'MongoDB is fun'}\n"
     ]
    }
   ],
   "source": [
    "for post in posts.find():\n",
    "    pprint.pprint(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f53a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n",
      "{'_id': ObjectId('6362e3038130e5fb6aa1aa47'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2009, 11, 12, 11, 14),\n",
      " 'tags': ['bulk', 'insert'],\n",
      " 'text': 'Another post!'}\n"
     ]
    }
   ],
   "source": [
    "for post in posts.find( {\"author\" : \"Mike\"} ):\n",
    "    pprint.pprint(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f6877",
   "metadata": {},
   "source": [
    "The number of documents in a collection, or the number of documents that match a set of criterea, can be retrieved using the **count_documents( )** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e9d89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Docs:  3\n",
      "Matching Docs:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"All Docs: \", posts.count_documents( {} ))\n",
    "print(\"Matching Docs: \", posts.count_documents( {\"author\" : \"Mike\"} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd96f8",
   "metadata": {},
   "source": [
    "Many advanced querying techniques can be achieved using MongoDB. For example, the following **range query** retrieves all documents older than *November 12, 2009*, sorted by *author*.  The equivalent SQL query would be **SELECT * FROM posts WHERE date < '2009-11-12:12.0.0:00' ORDER BY author**.\n",
    "\n",
    "Notice here that in order to specify the range **less than**, the special operator **$lt** was used, and that the comparison was nested within curly braces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc38aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e2378130e5fb6aa1aa46'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2022, 11, 2, 21, 33, 43, 634000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n"
     ]
    }
   ],
   "source": [
    "d = datetime.datetime(2009, 11, 12, 12)\n",
    "\n",
    "for post in posts.find({\"date\": {\"$gt\": d}}).sort(\"author\"):\n",
    "    pprint.pprint(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3287257",
   "metadata": {},
   "source": [
    "### 5.0. Indexes, Unique Constraints and Primary Keys\n",
    "\n",
    "Also equivalent to relational database management systems are the use of **indexes** to expedite data retrieval, and to enforce **uniqueness** where desired.  When designing RDBMS tables, it is customary to create a **Primary Key** that uniquely identifies each observation (row).  By default, MongoDB creates an index on the **_id** field, but it may be desireable to enforce uniqueness on user-defined values such as we have seen with **customer_id, employee_id, product_id,** and **shipper_id**. To that affect, the following code creates an *unique* index on the *user_id* element that is sorted in *ascending* order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aafada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id_', 'jedi_id_1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = db.profiles.create_index([('jedi_id', pymongo.ASCENDING)], unique=True)\n",
    "sorted(list(db.profiles.index_information()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f610e01",
   "metadata": {},
   "source": [
    "Now, we can insert some new documents that leverage the new **user_id** unique key index..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e027cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.results.InsertManyResult object at 0x7fada1382c10>\n"
     ]
    }
   ],
   "source": [
    "jedi_profiles = [\n",
    "    {'jedi_id': 211, 'name': 'Luke'},\n",
    "    {'jedi_id': 212, 'name': 'Yoda'}]\n",
    "\n",
    "result = db.profiles.insert_many(jedi_profiles)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c1b6c",
   "metadata": {},
   "source": [
    "... but if we attempt to insert a record having a preexisting *user_id* then a **Duplicate Key error** will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "708987a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sith_profile = {'jedi_id': 213, 'name': 'Anakin'}\n",
    "result = db.profiles.insert_one(sith_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c7df9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6362e4148130e5fb6aa1aa49'), 'jedi_id': 211, 'name': 'Luke'}\n",
      "{'_id': ObjectId('6362e4148130e5fb6aa1aa4a'), 'jedi_id': 212, 'name': 'Yoda'}\n",
      "{'_id': ObjectId('6362e44f8130e5fb6aa1aa4c'), 'jedi_id': 213, 'name': 'Anakin'}\n"
     ]
    }
   ],
   "source": [
    "for profile in db.profiles.find():\n",
    "    pprint.pprint(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2fc11",
   "metadata": {},
   "source": [
    "### 6.0. Dropping Databases and Collections\n",
    "Of course what can be created can also be destroyed.  Here are the **pymongo** methods for dropping **collections** and **databases**.\n",
    "\n",
    "First, if you drop the last, or only, collection in a database then the entire database will be dropped as well... so first we'll create a second collection named **users** so we can demonstrate the methods for dropping collections and databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7645542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID:  6362e47c8130e5fb6aa1aa4e\n",
      "Databases:  ['admin', 'blog', 'config', 'local', 'mydb', 'test']\n",
      "Collections:  ['profiles', 'posts', 'users']\n"
     ]
    }
   ],
   "source": [
    "user = {\"first_name\" : \"John\",\n",
    "        \"last_name\" : \"Doe\",\n",
    "        \"role\" : \"administrator\"\n",
    "       }\n",
    "\n",
    "users = db.users\n",
    "user_id = users.insert_one(user).inserted_id\n",
    "\n",
    "print(\"User ID: \", user_id)\n",
    "print(\"Databases: \", client.list_database_names())\n",
    "print(\"Collections: \", db.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c43c24",
   "metadata": {},
   "source": [
    "Here we see that we've created a new **user** and subsequently a new collection **users**.  Now let's go ahead and drop the **posts** collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4296808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases:  ['admin', 'config', 'local', 'mydb', 'test']\n",
      "Collections:  []\n"
     ]
    }
   ],
   "source": [
    "for c in db.list_collection_names():\n",
    "    db.drop_collection(c)\n",
    "\n",
    "print(\"Databases: \", client.list_database_names())\n",
    "print(\"Collections: \", db.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b48710",
   "metadata": {},
   "source": [
    "So now we just have the **users** collection in the **blog** database. Now let's go ahead and drop the **blog** database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc74263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local', 'mydb', 'test']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b03c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return Value:  None\n",
      "Databases:  ['admin', 'config', 'local', 'mydb', 'test']\n",
      "Collections:  []\n"
     ]
    }
   ],
   "source": [
    "result = client.drop_database(db_name)\n",
    "\n",
    "print(\"Return Value: \", result)\n",
    "print(\"Databases: \", client.list_database_names())\n",
    "print(\"Collections: \", db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602daade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
